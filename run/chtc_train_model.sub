# submit file for VAEs in Pytorch
# TODO: make this consistent with other submit files
# TODO: variable capitalization is inconsistent

# Must set the universe to Docker
universe = docker
docker_image = romerolab/chtc:pytorch-nvidia-v16Dec19

# set the log, error and output files
log = logs/chtc_model_training_$(Cluster)_$(Process).log
error = logs/chtc_model_training_$(Cluster)_$(Process).err
output = logs/chtc_model_training_$(Cluster)_$(Process).out


# set the executable to run
executable = chtc_train_model.sh
# arguments = $(Cluster) $(Process) $(dataset) $(hidden) $(latent) $(config)
arguments = $(Cluster)_$(Process) ../$(config)

# take our python script and data to the compute node
#transfer_input_files = ../staging.tar.gz, ../chtc_root.txt, ../chtc_train_model.sh, $(squid)/sequences.tar.gz
transfer_input_files = staging.tar.gz, chtc_root.txt, sequences.tar.gz, ../$(config)

should_transfer_files = YES
when_to_transfer_output = ON_EXIT
  
# We must request 1 CPU in addition to 1 GPU (if needed)
request_cpus = 1

if ! defined DISABLE_GPU
# condor_submit was run from the command line like 
# condor_submit DISABLE_GPU=1 chtc_reweighting.sub
  request_gpus = 1
  # We require a machine with a modern version of the CUDA driver
  Requirements = (Target.CUDADriverVersion >= 10.1) && (Target.CUDACapability >= 5)

  +WantGPULab = true
  +GPUJobLength = "short"

endif

# select some memory and disk space
request_memory = 4GB
request_disk = 1GB

if ! defined DISABLE_FLOCKING
    +WantFlocking = false
endif

# Tell HTCondor to run on each dataset in datasets.txt
# queue dataset,hidden,latent from datasets.txt
#queue config from run/example_configs.txt
queue config from (config.yaml)
