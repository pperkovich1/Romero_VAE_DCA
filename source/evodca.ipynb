{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "\n",
    "import dca\n",
    "import evo_weight_tools\n",
    "\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODON_MAP = dataloader.codon_map\n",
    "qc = len(CODON_MAP) # qc = 61\n",
    "\n",
    "\n",
    "AA_MAP =  dataloader.AA_map_str.copy()\n",
    "if '-' in AA_MAP:\n",
    "    del AA_MAP['-']\n",
    "qa = len(AA_MAP) # qa = 20\n",
    "INV_AA_MAP = {v:k for k,v in AA_MAP.items()}\n",
    "\n",
    "\n",
    "#CODON_AA_MAP\n",
    "CODON_AA_MAP = np.array([AA_MAP[dataloader.codon_table.forward_table[c]] for \n",
    "                         c, idx in CODON_MAP.items()], dtype=np.int)\n",
    "CODON_AA_MAP = torch.from_numpy(CODON_AA_MAP)\n",
    "\n",
    "# Binary matrix that translates between Codon index and Amino Acid index\n",
    "codon_aa_mat = torch.eye(len(AA_MAP))[CODON_AA_MAP].float() # shape (qc, qa) binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_msa(filename):\n",
    "    ret = evo_weight_tools.get_codon_msa_as_int_array(filename, dataloader.codon_map)\n",
    "    return torch.ByteTensor(ret)\n",
    "\n",
    "def load_weights(filename):\n",
    "    return torch.FloatTensor(np.load(filename))\n",
    "\n",
    "def load_msa_weights(round_num):\n",
    "    msa_round = load_msa(f\"./data_test/Round{round_num}_Q15_C10_nts.aln.gz\")\n",
    "    weights_round = load_weights(f\"./data_test/Round{round_num}_weights.npy\")\n",
    "    return msa_round, weights_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sequences: 186\n",
      "MSA shape: torch.Size([19973, 186])\n",
      "Weights shape: torch.Size([19973, 186, 61])\n"
     ]
    }
   ],
   "source": [
    "# Load all the MSAs (pytorch ints) and evo weights (floats) \n",
    "# and concatenate them together\n",
    "msa_weights_zip = zip(*map(load_msa_weights, [1,2]))\n",
    "msa_int = torch.cat(next(msa_weights_zip))\n",
    "weights = torch.cat(next(msa_weights_zip))\n",
    "del(msa_weights_zip)\n",
    "L = msa_int.shape[1]\n",
    "print(f\"Length of sequences: {L}\")\n",
    "print(f\"MSA shape: {msa_int.shape}\")\n",
    "print(f\"Weights shape: {weights.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_one_hot = torch.nn.functional.one_hot(msa_int.long(), qc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvoDCA(dca.DCA):\n",
    "    \n",
    "    def forward(self, x, log_proposal):\n",
    "        \"\"\"`x` is a one-hot encoded MSA (or subset of an MSA) Shape: (n, L, q)\n",
    "           `log_proposal` is the weights computed by evo_weight_tools Shape: (n, L, q)\n",
    "        \"\"\"\n",
    "        x_msa = x\n",
    "        w_eye = self.w * self.weights_eye\n",
    "        self.weights = w_eye + w_eye.permute(2,3,0,1)\n",
    "        \n",
    "        # convert weights and biases to codon level params\n",
    "        weights_codon = self.weights.index_select(1, \n",
    "                                CODON_AA_MAP).index_select(3, CODON_AA_MAP)\n",
    "        bias_codon = self.bias.index_select(1, CODON_AA_MAP)\n",
    "        \n",
    "        # calculate logits with codon params and add in log_proposal\n",
    "        x_logit = torch.tensordot(x_msa, weights_codon, 2) + bias_codon + log_proposal\n",
    "        return x_logit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_count = 0.01 \n",
    "\n",
    "with torch.no_grad():\n",
    "    b_ini = torch.matmul(msa_one_hot.float(), codon_aa_mat) + pseudo_count\n",
    "    b_ini = torch.log(b_ini.mean(0))\n",
    "    model = EvoDCA(ncol=L, \n",
    "                   ncat=qa, # Initialize DCA model with number of amino acids and not\n",
    "                            # number of codons as that is the shape of our params\n",
    "                   Neff=1e4, # ??Not sure what we should set this to\n",
    "                   b_ini = b_ini)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
