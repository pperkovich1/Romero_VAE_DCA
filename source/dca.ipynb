{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing DCA in pytorch\n",
    "\n",
    "Source CC function in [seqmodel](https://github.com/sokrypton/seqmodels/blob/master/seqmodels.ipynb)\n",
    "Reimplemeting tensorflow code in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import read_config\n",
    "from dataloader import MSADataset, OneHotTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14441, 559)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = read_config.Config(\"../config2d.yaml\")\n",
    "dataset = MSADataset(config.aligned_msa_fullpath, transform=OneHotTransform(21, flatten=False))\n",
    "\n",
    "N = len(dataset)\n",
    "\n",
    "protein_seq, weight = dataset[0]\n",
    "ncat = 21\n",
    "L = protein_seq.shape[0]\n",
    "ncol = L\n",
    "\n",
    "N, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([559, 21])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(559, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncol, ncat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data.shape = torch.Size([128, 559, 21])\n",
      "Weights.shape = torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "batch_size = config.batch_size\n",
    "#batch_size = len(dataset) ## to load in the whole dataset\n",
    "msa = torch.utils.data.DataLoader(dataset, batch_size)\n",
    "\n",
    "for _, msa_data in enumerate(msa):\n",
    "    data  = msa_data[0]\n",
    "    seq_weights = msa_data[1]\n",
    "    break\n",
    "    \n",
    "print(f\"Data.shape = {data.shape}\")\n",
    "print(f\"Weights.shape = {seq_weights.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = torch.zeros((ncol,ncat), dtype=torch.float, requires_grad=True, device=device)\n",
    "w = torch.zeros((ncol, ncat, ncol, ncat), dtype=torch.float, requires_grad=True, device=device)\n",
    "\n",
    "optimizer = torch.optim.SGD([bias, w], lr=config.learning_rate)\n",
    "\n",
    "# we do not want weights between the various nodes in a given position. \n",
    "# i.e. weights between nodes (i, a) and (j, b) only exist if i not = j\n",
    "# so set these weights to zero\n",
    "w_eye = w * torch.reshape(1 - torch.eye(ncol), (ncol,1,ncol, 1))\n",
    "# symmetrize w so that the weight between (i,a) and (j, b) is the\n",
    "# same as the weight between (j, b) and (i, a)\n",
    "weights = w_eye + w_eye.permute(2,3,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(device)\n",
    "seq_weights = seq_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_seq_weights = torch.sum(seq_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_func = torch.nn.Softmax(-1)\n",
    "loss_func = torch.nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 559, 21])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_logit = torch.tensordot(data, weights, 2) + bias\n",
    "data_logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(data_logit.permute(0,2,1), data.argmax(dim=2))\n",
    "loss = loss.sum(dim=-1)\n",
    "loss = (loss * seq_weights).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 regularization\n",
    "lam_w = 0.1\n",
    "lam_b = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = lam_w * torch.sum(torch.mul(weights, weights)) * 0.5 * (ncol-1) * 20.0 \n",
    "reg += lam_b * torch.sum(torch.mul(bias, bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1701.8884, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = (loss + reg) / sum_seq_weights\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
