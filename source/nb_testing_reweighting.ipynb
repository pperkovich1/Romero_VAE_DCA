{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_filename = \"../sequence_sets/cmx_aligned_blank_90.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "seqs = [list(str(seq.seq.upper())) for seq in SeqIO.parse(seq_filename, \"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14441, 559)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[b'K', b'N', b'A', ..., b'Q', b'A', b'D'],\n",
       "       [b'E', b'D', b'A', ..., b'Q', b'A', b'D'],\n",
       "       [b'K', b'D', b'A', ..., b'Q', b'A', b'D'],\n",
       "       ...,\n",
       "       [b'-', b'-', b'-', ..., b'-', b'-', b'-'],\n",
       "       [b'-', b'-', b'-', ..., b'-', b'-', b'-'],\n",
       "       [b'-', b'-', b'A', ..., b'-', b'-', b'-']], dtype='|S1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa = np.array(seqs, dtype=\"|S1\")\n",
    "print(msa.shape)\n",
    "N, L = msa.shape # set the number of sequences and the length of the protein\n",
    "msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14441, 559)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#msa = msa[:10000, :] # for testing\n",
    "msa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14441, 559])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[75, 78, 65,  ..., 81, 65, 68],\n",
       "        [69, 68, 65,  ..., 81, 65, 68],\n",
       "        [75, 68, 65,  ..., 81, 65, 68],\n",
       "        ...,\n",
       "        [45, 45, 45,  ..., 45, 45, 45],\n",
       "        [45, 45, 45,  ..., 45, 45, 45],\n",
       "        [45, 45, 65,  ..., 45, 45, 45]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "\n",
    "msa_int = torch.ByteTensor(msa.view(np.uint8))\n",
    "print(msa_int.shape)\n",
    "msa_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_to_threshold = 0.8 # Hamming distance >= 80%\n",
    "\n",
    "epsilon = 1e-6 # to avoid rounding issues in the unlikely event there are any\n",
    "distance_from_threshold_int = int((1 - distance_to_threshold) * L + epsilon)\n",
    "distance_from_threshold_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a torch scalar for the threshold\n",
    "torch_threshold = torch.ShortTensor(1)\n",
    "torch_threshold[0] = distance_from_threshold_int\n",
    "torch_threshold = torch_threshold.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_int = msa_int.to(device) # move to device\n",
    "torch_seqs = torch.unbind(msa_int, dim=0) # split into separate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0625 0.0625 0.0625 ... 1.     0.5    1.    ]\n"
     ]
    }
   ],
   "source": [
    "def count_neighbors(torch_seq):\n",
    "    \"\"\"Count the neighbors of torch_seq in arr_int using torch_threshold as cutoff\"\"\"\n",
    "    dist_from_seq = (torch_seq != msa_int).sum(axis=1, dtype=torch.short)\n",
    "    threshold_count = (dist_from_seq <= torch_threshold).sum(dtype=torch.short)\n",
    "    return threshold_count\n",
    "\n",
    "neighbors_count = torch.stack(tuple(count_neighbors(torch_seq) for \n",
    "                                        torch_seq in torch_seqs))\n",
    "\n",
    "weights = 1 / neighbors_count.float() \n",
    "weights_np = weights.data.numpy()\n",
    "print (weights_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.23 min\n"
     ]
    }
   ],
   "source": [
    "print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch] *",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
